## üíª 1. An√°lise Funcional do Script de Carga (`locustfile.py`)

O script de teste de carga (`locustfile.py`) √© a ferramenta fundamental para simular o comportamento real dos usu√°rios na nossa aplica√ß√£o de chat. Ele foi desenhado para gerar carga no **M√≥dulo P (WEB API/Gateway)**, que √© o ponto de entrada das requisi√ß√µes, simulando assim a **intera√ß√£o colaborativa** com os M√≥dulos A e B, conforme a arquitetura distribu√≠da.

O script simula uma sess√£o de chat completa, incluindo tr√™s tipos de carga distintos:

---

### Estrutura Funcional e Tipos de Carga Simulada

| Se√ß√£o | Frequ√™ncia/Carga | Contexto e Fun√ß√£o no Teste |
| :--- | :--- | :--- |
| **Conex√£o Inicial** | Ocorre uma vez por usu√°rio virtual. | Simula o ato do usu√°rio **entrar no chat** (como 'Pedro' entrar na sala 'teste'). Essa a√ß√£o estabelece a conex√£o WebSocket e aciona o **M√≥dulo A (UserService gRPC)** para registrar o usu√°rio. Mede a lat√™ncia de login e estabelecimento da sess√£o. |
| **Envio de Mensagem** | **Alta Frequ√™ncia (80% da carga)**. | Simula o envio de uma mensagem de texto (Carga M√©dia). Essa √© a opera√ß√£o mais comum do chat e testa a performance do **M√≥dulo A (ChatService gRPC)** e a efici√™ncia do *fan-out* das mensagens pelo M√≥dulo P. |
| **Upload de Arquivo** | **Baixa Frequ√™ncia (20% da carga)** e **Carga Pesada**. | Simula o envio de um arquivo de 10KB. Esta opera√ß√£o envolve dois passos: o *upload* de dados (Carga Pesada) via HTTP para o M√≥dulo P, que aciona o **M√≥dulo B (FileService gRPC)** para armazenamento, e a subsequente notifica√ß√£o via WebSocket. Mede a lat√™ncia em opera√ß√µes de I/O intensivas. |

### Contexto de Observabilidade

Ao executar o teste com esse script realista, monitoramos a lat√™ncia e o RPS para cada uma das tr√™s opera√ß√µes. Essa granularidade √© essencial para identificar, atrav√©s do Prometheus/Grafana, qual m√≥dulo (P, A ou B) se torna o **gargalo** (por exemplo, alta CPU no M√≥dulo B em testes de Upload), permitindo direcionar as otimiza√ß√µes no Kubernetes com precis√£o.

---

## üìà Metodologia para Garantir Observabilidade e Desempenho

A metodologia adotada neste projeto visa identificar o arranjo ideal da aplica√ß√£o baseada em microservi√ßos gRPC no cluster Kubernetes (K8S) em modo *cluster*, buscando otimizar a **performance** e a **elasticidade**. Para isso, realizamos testes comparativos de carga focados na m√©trica de desempenho.

### Ferramentas e Ambiente Adotados

* **Arquitetura:** Aplica√ß√£o de chat em tempo real baseada em microservi√ßos **gRPC** (M√≥dulos P, A, B) com o **M√≥dulo P** atuando como **Gateway WebSocket/WEB API**.
* **Cluster K8S:** Estruturado com um N√≥ Mestre e, pelo menos, dois Worker Nodes, incluindo recursos de autoscaling.
* **Teste de Carga:** Adotamos o **Locust** para simular usu√°rios concorrentes, utilizando um *script* que simula o comportamento realista do chat (Conex√£o, Envio de Texto e Upload).
* **Monitoramento e Observabilidade:** O **Prometheus** foi instalado no K8S para coletar m√©tricas do ambiente e da aplica√ß√£o (CPU, Mem√≥ria, Lat√™ncia Interna) e o Grafana para a visualiza√ß√£o dessas m√©tricas.

### 1. An√°lise do Cen√°rio A: Identifica√ß√£o do Limite (Stress Test)

O objetivo desta fase foi determinar o limite operacional da **Configura√ß√£o Base** (1 r√©plica para P, A e B). Aumentamos o n√∫mero de usu√°rios ativos progressivamente (de 100 a 100.000 usu√°rios) para identificar o ponto de satura√ß√£o.

* **Foco da An√°lise:** Os testes revelaram que o principal gargalo n√£o √© o envio de mensagens (lat√™ncia do `/ws/chat/send_text` permaneceu em $0.01 \text{ ms}$ mesmo sob extrema carga), mas sim a **capacidade de estabelecer novas conex√µes**.
* **Ponto de Degrada√ß√£o:** A lat√™ncia m√©dia (`Average (ms)`) para estabelecer a conex√£o (`/ws/chat/connect`) aumentou significativamente a partir de **2.000 usu√°rios**, atingindo $69.57 \text{ ms}$ e, posteriormente, **$124.56 \text{ ms}$ com 100.000 usu√°rios**.
* **Identifica√ß√£o do Limite:** O sistema atinge o limite de *throughput* para mensagens em torno de **$290.9 \text{ RPS}$ com 5.000 usu√°rios**. A partir de 100.000 usu√°rios, o RPS de mensagens cai drasticamente para $0.5 \text{ RPS}$ devido √† falha massiva no estabelecimento da conex√£o.
* **Conclus√£o:** O limite de **elasticidade da Conex√£o** (Handshake WebSocket) do M√≥dulo P √© o principal fator limitante do sistema na configura√ß√£o atual.

### 2. Cen√°rio B: Configura√ß√£o Base (Baseline)

Com base nos resultados da Fase 1, estabelecemos a performance de refer√™ncia (Baseline).

* **Configura√ß√£o:** Aplica√ß√£o instanciada num cen√°rio simples (1 r√©plica para P, A e B).
* **Carga Adotada:** Utilizaremos uma carga de **2.000 usu√°rios (50 *ramp up*)** como Baseline, pois este √© o ponto onde o sistema ainda sustenta um alto RPS ($122.2 \text{ RPS}$) e a lat√™ncia de conex√£o, embora elevada ($69.57 \text{ ms}$), ainda √© considerada aceit√°vel para testes comparativos.
* **Valores do Baseline (Requisitos do Trabalho):**
    * **Tempo m√©dio para atender uma requisi√ß√£o (Conex√£o):** $\approx 69.57 \text{ ms}$.
    * **M√°xima quantidade de RPS sustent√°vel (Agregado):** $\approx 122.2 \text{ RPS}$.

### 3. Cen√°rio C: Cen√°rios Vari√°veis (Performance e Elasticidade)

Nesta fase, introduzimos varia√ß√µes no K8S, mantendo a carga est√°vel de **2.000 usu√°rios** (Baseline) para isolar o impacto da mudan√ßa no desempenho.

* **Varia√ß√£o de Elasticidade (HPA):** Ativaremos o **Horizontal Pod Autoscaler (HPA)** no **M√≥dulo P** (Gateway) para verificar se o K8S escala automaticamente novas r√©plicas de P em resposta √† alta CPU/Lat√™ncia de Conex√£o, resultando em uma **diminui√ß√£o na lat√™ncia m√©dia** do `/ws/chat/connect` e estabilizando o RPS.
* **Varia√ß√£o de R√©plicas (Performance):** Aumentaremos as r√©plicas dos **M√≥dulos A e B** para comprovar se os servidores gRPC estavam atuando como um gargalo de processamento.
* **Conclus√£o:** Para cada cen√°rio, o desempenho ser√° cruzado com o monitoramento do Prometheus para determinar a configura√ß√£o mais eficiente para garantir tanto a alta performance quanto a elasticidade do servi√ßo de chat.

---

## üöÄ Passo a Passo: Instala√ß√£o e Execu√ß√£o do Locust (Para Outros Membros)

Este passo a passo detalha a instala√ß√£o e execu√ß√£o do Locust no ambiente Linux, assumindo que o Python 3 e o `pip` est√£o instalados.

### 1. Pr√©-requisitos (Instala√ß√£o das Ferramentas)

A primeira etapa √© instalar as bibliotecas necess√°rias para rodar o Locust e lidar com as conex√µes WebSocket.

```bash
# 1. Instala o Locust e as bibliotecas WebSocket (gevent-websocket e websocket-client)
pip install locust gevent-websocket websocket-client