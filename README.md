# Projeto Distribu√≠do com gRPC

Este projeto implementa uma aplica√ß√£o distribu√≠da baseada em gRPC com tr√™s m√≥dulos principais: **P** (Gateway), **A** e **B** (Microservi√ßos).

## Arquitetura

```
WEB Client (HTTP) -> M√≥dulo P (Gateway/FastAPI) -> M√≥dulo A (gRPC/Node.js)
                                                 -> M√≥dulo B (gRPC/Node.js)
```

- **M√≥dulo P**: Gateway/Proxy em Python com FastAPI que recebe requisi√ß√µes HTTP e as converte em chamadas gRPC
- **M√≥dulo A**: Microservi√ßo gRPC em Node.js com m√©todo unary
- **M√≥dulo B**: Microservi√ßo gRPC em Node.js com m√©todo server-streaming

## Estrutura do Projeto

```
projeto_distribuido/
‚îú‚îÄ‚îÄ protos/
‚îÇ   ‚îî‚îÄ‚îÄ servico.proto           # Defini√ß√µes gRPC (mensagens e servi√ßos)
‚îú‚îÄ‚îÄ modulo_P/                   # Gateway FastAPI (Python)
‚îÇ   ‚îú‚îÄ‚îÄ app.py                  # Servidor FastAPI principal
‚îÇ   ‚îú‚îÄ‚îÄ generate_protos.py      # Script para gerar stubs Python
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt        # Depend√™ncias Python
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile              # Container do gateway
‚îú‚îÄ‚îÄ modulo_A/                   # Microservi√ßo A (Node.js)
‚îÇ   ‚îú‚îÄ‚îÄ server.js               # Servidor gRPC com m√©todo unary
‚îÇ   ‚îú‚îÄ‚îÄ package.json            # Depend√™ncias Node.js
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile              # Container do m√≥dulo A
‚îú‚îÄ‚îÄ modulo_B/                   # Microservi√ßo B (Node.js)
‚îÇ   ‚îú‚îÄ‚îÄ server.js               # Servidor gRPC com streaming
‚îÇ   ‚îú‚îÄ‚îÄ package.json            # Depend√™ncias Node.js
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile              # Container do m√≥dulo B
‚îú‚îÄ‚îÄ docker-compose.yml          # Orquestra√ß√£o dos servi√ßos
‚îî‚îÄ‚îÄ README.md                   # Este arquivo
```

## Requisitos

- **Docker** e **Docker Compose**
- **Python 3.11+** (para desenvolvimento local)
- **Node.js 18+** (para desenvolvimento local)

## Como rodar o sistema (tudo via Docker Compose)

1. Certifique-se de ter Docker e Docker Compose instalados.
2. No diret√≥rio raiz do projeto, execute:

```bash
docker compose up --build -d
```

3. Acesse o frontend em [http://localhost:3000](http://localhost:3000)
4. O gateway (M√≥dulo P) estar√° dispon√≠vel em [http://localhost:8000](http://localhost:8000)

5. Para ver logs em tempo real:

```bash
docker compose logs -f
```

6. Para parar tudo:

```bash
docker compose down
```

---

## Como alternar entre gRPC e REST/JSON

Para alternar entre gRPC e REST/JSON, edite o servi√ßo `modulo-p` no `docker-compose.yml`:

```yaml
environment:
  - MODOP_COMUNICACAO=rest # ou 'grpc' (padr√£o)
```

Depois, reinicie os containers:

```bash
docker compose up --build -d
```

---

## Como Usar

### 1. Verificar Status dos Servi√ßos

- **Gateway (M√≥dulo P)**: http://localhost:8000
- **Documenta√ß√£o da API**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

### 2. Fazer Requisi√ß√µes

**Endpoint Principal**: `POST http://localhost:8000/api/executar`

**Payload de exemplo**:

```json
{
  "id": "tarefa-001",
  "data": "dados_de_teste",
  "operation": "uppercase",
  "count": 3
}
```

**Exemplo com curl**:

```bash
curl -X POST "http://localhost:8000/api/executar" \
     -H "Content-Type: application/json" \
     -d '{
       "id": "tarefa-001",
       "data": "hello_world",
       "operation": "uppercase",
       "count": 3
     }'
```

### 3. Resposta Esperada

```json
{
  "request_id": "tarefa-001",
  "resultado_a": {
    "id": "tarefa-001",
    "result": "HELLO_WORLD_PROCESSED_AT_2025-09-29T10:30:00.000Z",
    "message": "Tarefa A executada com sucesso para ID tarefa-001",
    "status_code": 200
  },
  "resultados_b": [
    {
      "id": "tarefa-001",
      "result": "hello_world_processado_por_A:HELLO_WORLD_PROCESSED_AT_2025-09-29T10:30:00.000Z_chunk_1_analyzed_progress_33.3%_at_2025-09-29T10:30:01.000Z",
      "message": "Resposta 1 de 3 do ServicoB",
      "sequence_number": 1,
      "is_final": false
    },
    {
      "id": "tarefa-001",
      "result": "hello_world_processado_por_A:HELLO_WORLD_PROCESSED_AT_2025-09-29T10:30:00.000Z_chunk_2_transformed_progress_66.7%_at_2025-09-29T10:30:02.000Z",
      "message": "Resposta 2 de 3 do ServicoB",
      "sequence_number": 2,
      "is_final": false
    },
    {
      "id": "tarefa-001",
      "result": "hello_world_processado_por_A:HELLO_WORLD_PROCESSED_AT_2025-09-29T10:30:00.000Z_chunk_3_enriched_progress_100.0%_at_2025-09-29T10:30:03.000Z",
      "message": "Resposta 3 de 3 do ServicoB",
      "sequence_number": 3,
      "is_final": true
    }
  ],
  "status": "success",
  "message": "Tarefa tarefa-001 executada com sucesso. M√≥dulo A processou, M√≥dulo B retornou 3 respostas."
}
```

## Testando os Endpoints REST dos M√≥dulos A e B

Voc√™ pode testar os microsservi√ßos REST/JSON (modulo_A e modulo_B) diretamente usando `curl` ou Postman.

### M√≥dulo A (REST)

Inicie o servidor REST do m√≥dulo A:

```bash
cd modulo_A
npm install express
node server_rest.js
```

Teste o endpoint:

```bash
curl -X POST http://localhost:5001/realizar-tarefa-a \
  -H "Content-Type: application/json" \
  -d '{"id":1,"data":"exemplo","operation":"upper"}'
```

Resposta esperada:

```json
{ "id": 1, "resultado": "EXEMPLO", "status": "ok" }
```

### M√≥dulo B (REST)

Inicie o servidor REST do m√≥dulo B:

```bash
cd modulo_B
npm install express
node server_rest.js
```

Teste o endpoint:

```bash
curl -X POST http://localhost:5002/realizar-tarefa-b \
  -H "Content-Type: application/json" \
  -d '{"id":2,"data":"exemplo","count":3}'
```

Resposta esperada:

```json
{
  "id": 2,
  "respostas": [
    { "id": 2, "resultado": "exemplo-resp1", "ordem": 1, "status": "ok" },
    { "id": 2, "resultado": "exemplo-resp2", "ordem": 2, "status": "ok" },
    { "id": 2, "resultado": "exemplo-resp3", "ordem": 3, "status": "ok" }
  ],
  "total": 3
}
```

## Fluxo de Execu√ß√£o

1. **Cliente Web** faz requisi√ß√£o HTTP POST para `/api/executar`
2. **M√≥dulo P** recebe a requisi√ß√£o e:
   - Chama o **M√≥dulo A** via gRPC (m√©todo unary)
   - Usa a resposta do **M√≥dulo A** para chamar o **M√≥dulo B** via gRPC (m√©todo server-streaming)
   - Consolida as respostas e retorna ao cliente como JSON

## Opera√ß√µes Dispon√≠veis (M√≥dulo A)

- `uppercase`: Converte para mai√∫sculas
- `lowercase`: Converte para min√∫sculas
- `reverse`: Inverte a string
- `length`: Retorna o comprimento
- `default`: Processamento padr√£o

## Teste de Performance: Comparativo gRPC vs REST/JSON

O script `documentacao/teste_performance.py` permite comparar o tempo de resposta do endpoint principal do M√≥dulo P, tanto usando gRPC quanto REST/JSON.

### Para que serve?

Esse script faz m√∫ltiplas requisi√ß√µes POST para o endpoint `/api/executar` do M√≥dulo P e mede o tempo de resposta m√©dio, m√≠nimo e m√°ximo. Voc√™ pode alternar o modo de comunica√ß√£o do M√≥dulo P (gRPC ou REST) e comparar os resultados para cada abordagem.

### Como usar

1. **Crie e ative um ambiente virtual Python:**

```bash
python3 -m venv venv
source venv/bin/activate
```

2. **Instale a depend√™ncia necess√°ria:**

```bash
pip install requests
```

3. **Execute o script de teste:**

```bash
python documentacao/teste_performance.py
```

4. **Altere o modo de comunica√ß√£o do M√≥dulo P:**

- Para testar gRPC, mantenha `MODOP_COMUNICACAO=grpc` (padr√£o)
- Para testar REST, defina `MODOP_COMUNICACAO=rest` antes de iniciar o M√≥dulo P:
  ```bash
  export MODOP_COMUNICACAO=rest
  python app.py
  ```

5. **Compare os resultados exibidos pelo script** (tempo m√©dio, menor e maior tempo).

### Exemplo de sa√≠da

```
Testando 10 requisi√ß√µes para http://localhost:8000/api/executar
Tempo m√©dio: 3.0348 segundos
Menor tempo: 3.0304 s | Maior tempo: 3.0500 s
Altere o modo de comunica√ß√£o do M√≥dulo P (gRPC/REST) e repita o teste.
```

## Monitoramento

### Logs dos Servi√ßos

```bash
# Ver logs de todos os servi√ßos
docker-compose logs -f

# Ver logs de um servi√ßo espec√≠fico
docker-compose logs -f modulo-a
docker-compose logs -f modulo-b
docker-compose logs -f modulo-p
```

### Health Checks

Os servi√ßos incluem health checks configurados no Docker Compose:

```bash
# Verificar status dos containers
docker-compose ps
```

## Desenvolvimento

### Modificar o Arquivo .proto

Quando modificar `protos/servico.proto`:

1. **Para o M√≥dulo P**:

```bash
cd modulo_P
python generate_protos.py
```

2. **Para os M√≥dulos A e B**:
   Os stubs s√£o carregados dinamicamente, n√£o √© necess√°rio regenerar.

### Debugging

Para debugging local, voc√™ pode executar cada m√≥dulo separadamente:

1. Primeiro inicie os m√≥dulos A e B
2. Depois inicie o m√≥dulo P
3. Use as portas padr√£o: A (50051), B (50052), P (8000)

## Portas Utilizadas

- **M√≥dulo P (Gateway)**: 8000 (HTTP)
- **M√≥dulo A**: 50051 (gRPC)
- **M√≥dulo B**: 50052 (gRPC)

## Parar os Servi√ßos

```bash
# Parar todos os servi√ßos
docker-compose down

# Parar e remover volumes
docker-compose down -v

# For√ßar reconstru√ß√£o na pr√≥xima execu√ß√£o
docker-compose down --rmi all
```

## üåê Frontend para Testes

O frontend j√° est√° incluso no Docker Compose. Basta rodar:

```bash
docker compose up --build -d
```

E acessar no navegador:

```
http://localhost:3000
```

Funcionalidades do Frontend:

- ‚úÖ **Teste Principal**: Testa o fluxo completo (Gateway ‚Üí M√≥dulo A ‚Üí M√≥dulo B)
- ‚úÖ **Teste M√≥dulo A**: Testa diretamente o endpoint REST do M√≥dulo A
- ‚úÖ **Teste M√≥dulo B**: Testa diretamente o endpoint REST do M√≥dulo B
- ‚úÖ **Interface Simples**: Formul√°rios intuitivos para todos os testes
- ‚úÖ **Auto-start**: M√≥dulos REST iniciam automaticamente

## Compara√ß√£o de Desempenho gRPC x REST no Frontend

O frontend web deste projeto possui um painel de **Compara√ß√£o gRPC x REST** que permite comparar, de forma pr√°tica e visual, o tempo de resposta entre os dois tipos de comunica√ß√£o.

### Como funciona o teste de compara√ß√£o

- O frontend envia **5 requisi√ß√µes** para o gateway (gRPC) e para o endpoint REST do M√≥dulo A.
- Para gRPC, a requisi√ß√£o segue o fluxo: **Frontend ‚Üí Gateway (FastAPI) ‚Üí gRPC ‚Üí M√≥dulo A (Node.js)**.
- Para REST, a requisi√ß√£o vai **direto do Frontend para o endpoint REST do M√≥dulo A (Node.js)**.
- O tempo de resposta de cada requisi√ß√£o √© medido individualmente e a m√©dia dos tempos √© calculada para cada abordagem.
- O resultado mostra:
  - A m√©dia dos tempos de resposta para gRPC e REST
  - Os tempos individuais de cada requisi√ß√£o
  - A diferen√ßa m√©dia entre gRPC e REST
  - Indica√ß√£o visual de qual abordagem foi mais r√°pida

### O que est√° sendo comparado?

- **gRPC (via gateway):** Mede o tempo total do caminho Frontend ‚Üí FastAPI (gateway) ‚Üí gRPC ‚Üí Node.js ‚Üí resposta. Inclui o overhead do gateway e do protocolo gRPC.
- **REST (direto):** Mede o tempo do caminho Frontend ‚Üí Node.js (REST) ‚Üí resposta, sem intermedi√°rios.

## Deploy com Kubernetes (Minikube)

Esta se√ß√£o detalha como implantar a aplica√ß√£o em um cluster Kubernetes local utilizando o Minikube, simulando um ambiente de produ√ß√£o Cloud Native.

### Arquivos de Configura√ß√£o

O deploy no Kubernetes √© definido de forma declarativa atrav√©s dos arquivos de manifesto (`.yaml`) localizados na pasta `kubernetes/`.

- `01-namespace.yaml`: Cria um espa√ßo de trabalho isolado chamado `projeto-distribuido` para organizar todos os recursos da nossa aplica√ß√£o.
- `modulo-a-deployment.yaml`: Define o estado desejado para o M√≥dulo A, especificando a imagem Docker a ser usada e o n√∫mero de r√©plicas.
- `modulo-a-service.yaml`: Exp√µe o M√≥dulo A internamente no cluster (`ClusterIP`), permitindo que o Gateway P o encontre atrav√©s do nome `modulo-a-service`.
- `modulo-b-deployment.yaml`: Define o estado desejado para o M√≥dulo B.
- `modulo-b-service.yaml`: Exp√µe o M√≥dulo B internamente no cluster (`ClusterIP`) com o nome `modulo-b-service`.
- `modulo-p-deployment.yaml`: Define o estado desejado para o M√≥dulo P (Gateway).
- `modulo-p-service.yaml`: Exp√µe o Gateway para acesso externo atrav√©s de uma porta no n√≥ do cluster (`NodePort`), tornando a aplica√ß√£o acess√≠vel para o usu√°rio.

### Instru√ß√µes para o Deploy do Backend

O script `kubernetes_start.sh` automatiza todo o processo de deploy do backend.

1.  **D√™ permiss√£o de execu√ß√£o ao script:**

    ```bash
    chmod +x kubernetes_start.sh
    ```

2.  **Execute o script de deploy:**
    ```bash
    ./kubernetes_start.sh
    ```
    O script ir√° realizar as seguintes etapas:
    - Verificar se Docker e Minikube est√£o instalados.
    - Iniciar o cluster Minikube.
    - Conectar o ambiente Docker ao daemon do Minikube.
    - Construir as imagens Docker dos tr√™s m√≥dulos.
    - Aplicar todos os manifestos `.yaml` na ordem correta.
    - Aguardar at√© que todos os Pods estejam no estado `Running`.

### Acessando a Aplica√ß√£o (Frontend + Backend)

Ap√≥s o script `kubernetes_start.sh` finalizar, seu backend estar√° rodando no Kubernetes. Para interagir com a aplica√ß√£o atrav√©s da interface web, siga os passos:

1.  **Obtenha a URL do Backend (Gateway):**
    Abra um **novo terminal** e execute o comando abaixo para descobrir o endere√ßo do seu gateway.

    ```bash
    minikube service modulo-p-service -n projeto-distribuido --url
    ```

    Copie a URL retornada (algo como `http://192.168.49.2:30385`).

2.  **Inicie o Servidor do Frontend:**
    Ainda no mesmo terminal, navegue at√© a pasta `frontend` e inicie o servidor, passando a URL do backend como uma vari√°vel de ambiente. Substitua `<URL_DO_MINIKUBE>` pela URL que voc√™ copiou.

    **No Linux/macOS:**

    ```bash
    export GATEWAY_URL="<URL_DO_MINIKUBE>"
    cd frontend
    npm install  # Execute apenas na primeira vez
    npm start
    ```

    **No Windows (PowerShell):**

    ```powershell
    $env:GATEWAY_URL="<URL_DO_MINIKUBE>"
    cd frontend
    npm install  # Execute apenas na primeira vez
    npm start
    ```

3.  **Acesse a Interface Web:**
    Abra seu navegador e acesse a URL do frontend, que estar√° rodando localmente:
    ```
    http://localhost:3000
    ```
    A interface agora estar√° conectada ao seu backend no Kubernetes e todos os testes funcionar√£o.

### Gerenciamento do Ambiente

- **Para pausar o cluster** e liberar os recursos (CPU/RAM) do seu computador, execute:
  ```bash
  minikube stop
  ```
- **Para retomar o trabalho**, simplesmente reinicie o cluster (√© mais r√°pido que a primeira vez):
  ```bash
  minikube start
  ```
- **Para apagar completamente o cluster** e todos os recursos, execute:
  ```bash
  minikube delete
  ```

## Entrega

- O relat√≥rio e v√≠deo de apresenta√ß√£o est√° dispon√≠vel em: [`relatorio.md`](./relatorio.md)
